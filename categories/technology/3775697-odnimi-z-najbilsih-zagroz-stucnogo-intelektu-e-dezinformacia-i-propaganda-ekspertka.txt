Одними з найбільших загроз штучного інтелекту є дезінформація і масове поширення пропаганди, які генеруються за допомогою цієї технології. Тому зараз у світі намагаються розробити віртуальних асистентів, котрі швидко надавали б дані щодо правдивості інформації.

Як передає Укрінформ, про це в ефірі Українського радіо повідомила юристка, членкиня Комітету Мінцифри з питань розвитку штучного інтелекту Ольга Петрів.
Розповідаючи про небезпеки, пов'язані із застосуванням ШІ, вона зазначила: "Однією із найбільших загроз є дезінформація і масове поширення пропаганди, які генеруються за допомогою технології штучного інтелекту. Те, що може відбуватися із нашим суспільством і про що каже багато людей, які займаються розвитком систем штучного інтелекту, – у нас зараз буде презумпція брехні порівняно зі споживанням інформації раніше".
За словами Петрів, у людей досить часто є необґрунтована довіра до медіа: "З аналітичних даних випливає, що люди споживають багато інформації в інтернеті, в різноманітних пабліках та соцмережах. І, враховуючи те, наскільки легко зараз генерувати максимально правдоподібні сайти, імітувати їх, мімікрувати під відомі медіа, то дезінформація, яка так поширюється масово, вона зовсім скоро може заполонити мережу інтернет, і тоді презумпція брехні буде потужніше розвиватися".
Експертка уточнила, що така кількість згенерованої дезінформації, особливо під час різноманітних політичних процесів, виборчих кампаній якраз і зумовлює те, що людям потрібно набагато більше джерел та ресурсів витратити, аби перевірити, чи це дійсно правда. Зараз довіряти будь-якій інформації у будь-якому джерелі іноді стає досить ризиковано. Враховуючи, наприклад, те, як це може вплинути на репутацію, якщо зробити репост сумнівного матеріалу, додала вона.
За даними Петрів, для уникнення споживання такої інформації фахівці намагаються розробити таких віртуальних асистентів, які з мінімально витраченим часом швидко надавали б дані щодо правдивості інформації. "І ці віртуальні асистенти повинні працювати, базуючись на штучному інтелекті. В найближчому майбутньому на це треба орієнтуватися", – зазначила вона.
Експертка також розповіла, що Україна бере участь в запуску пілотного проєкту з регулювання ШІ, який розробляється Радою Європи. "Це методологія, за допомогою якої визначається, як система ШІ впливає на права людини, верховенство права і демократію, як вона потенційно впливатиме на це. І чи порушуватимуться ці права. Відбувається обговорення щодо регуляції – це те, що було викладено в дорожній карті. Це контрольоване середовище, де стартапи або компанії від початку створення і в процесі їхнього розвитку можуть перебувати в контрольованому середовищі, в межах якого вони спроможні найкраще розвивати свої системи, щоби вони відповідали вимогам акту. Того акту, який буде у ЄС (Закону про штучний інтелект, AI Act – ред.), в дорожній карті. Це також і секторальні рекомендації", – уточнила Петрів.
Як повідомляв Укрінформ, Міністерство цифрової трансформації розробило дорожню карту регулювання штучного інтелекту в Україні.
У червні 2023 року Європейський парламент схвалив проєкт, який ляже в основу майбутнього закону щодо правил регулювання штучного інтелекту.